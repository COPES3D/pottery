{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "from random import *\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flist=os.listdir(\"./data/npy_10000/list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_shards=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flist1=flist[:2000]\n",
    "flist2=flist[2000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# shards>20 print\n",
    "for filelist in flist2:\n",
    "    fstr=filelist.split('_')\n",
    "#     print(file)\n",
    "    filenames=[line.rstrip() for line in open(\"./data/npy_10000/list/\"+filelist,'r')]\n",
    "    temp_list=[]\n",
    "    temp_label=[]\n",
    "    for i in range(0,len(filenames)): #한 도자기 마다 생성중\n",
    "        if filenames[i]==\"\":\n",
    "            continue\n",
    "        npydata=np.load(\"./data/npy_10000/npy/\"+filenames[i]+\".npy\")\n",
    "        np.random.shuffle(npydata)\n",
    "        if npydata.shape[0]<2048:\n",
    "            continue\n",
    "        else:\n",
    "            temp_j_list=[]\n",
    "            for j in range(0,2048):\n",
    "                temp_j_list.append([npydata[j][0], npydata[j][1], npydata[j][2]])\n",
    "            \n",
    "            temp_list.append(temp_j_list)\n",
    "            temp_label.append(int(fstr[1])-1)\n",
    "\n",
    "    if len(temp_list) > max_shards:\n",
    "        print(\"filenames: \"+str(filenames))\n",
    "#         print(\"randomseed: \"+fstr(3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(flist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filelist in flist:\n",
    "    fstr=filelist.split('_')\n",
    "    #fstr(3) = randomseed\n",
    "    for i in range(len(flist)):\n",
    "        for j in range(len(flist)):\n",
    "            if i == j:\n",
    "                continue\n",
    "            if flist[i].split('_')[3] == flist[j].split('_')[3]:\n",
    "                print( flist[i] + '=' + flist[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if flist[0].split('_')[3] == flist[40].split('_')[3]:\n",
    "    print('yes')\n",
    "else:\n",
    "    print('no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filelist in flist:\n",
    "    fstr=filelist.split('_')\n",
    "    #fstr(3) = randomseed\n",
    "    for i in range(len(flist)):\n",
    "        for j in range(len(flist)):\n",
    "            if i == j:\n",
    "                continue\n",
    "            if flist[i].split('_')[3] == flist[j].split('_')[3]:\n",
    "                if flist[i].split('_')[2] == flist[j].split('_')[2]:\n",
    "                    print( flist[i] + '=' + flist[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnpy= os.listdir(\"./data/npy_10000/npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1=np.load('./data/npy_10000/npy/generated_6_0_2921_part_1.npy')\n",
    "a2=np.load('./data/npy_10000/npy/generated_6_0_2921_part_2.npy')\n",
    "a3=np.load('./data/npy_10000/npy/generated_6_0_2921_part_3.npy')\n",
    "a4=np.load('./data/npy_10000/npy/generated_6_0_2921_part_4.npy')\n",
    "a5=np.load('./data/npy_10000/npy/generated_6_0_2921_part_5.npy')\n",
    "a6=np.load('./data/npy_10000/npy/generated_6_0_2921_part_6.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a1.mean(axis=0))\n",
    "print(a2.mean(axis=0))\n",
    "print(a3.mean(axis=0))\n",
    "print(a4.mean(axis=0))\n",
    "print(a5.mean(axis=0))\n",
    "print(a6.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b1=np.load('./data/npy_10000/npy/generated_8_0_638880_part_1.npy')\n",
    "b2=np.load('./data/npy_10000/npy/generated_8_0_638880_part_2.npy')\n",
    "b3=np.load('./data/npy_10000/npy/generated_8_0_638880_part_3.npy')\n",
    "b4=np.load('./data/npy_10000/npy/generated_8_0_638880_part_4.npy')\n",
    "b5=np.load('./data/npy_10000/npy/generated_8_0_638880_part_5.npy')\n",
    "b6=np.load('./data/npy_10000/npy/generated_8_0_638880_part_6.npy')\n",
    "b7=np.load('./data/npy_10000/npy/generated_8_0_638880_part_7.npy')\n",
    "b8=np.load('./data/npy_10000/npy/generated_8_0_638880_part_8.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(b1.mean(axis=0))\n",
    "print(b2.mean(axis=0))\n",
    "print(b3.mean(axis=0))\n",
    "print(b4.mean(axis=0))\n",
    "print(b5.mean(axis=0))\n",
    "print(b6.mean(axis=0))\n",
    "print(b7.mean(axis=0))\n",
    "print(b8.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=np.load('./data/npy_10000/npy/'+fnpy[0])\n",
    "e= np.zeros(c.shape)\n",
    "e.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(c.shape)\n",
    "print(d.shape)\n",
    "print(c.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(c)):\n",
    "    for j in range(3):\n",
    "        d[i][j]=c[i][j]-c.mean(axis=0)[j]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.mean(axis=0)\n",
    "d.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(c.max(axis=0))\n",
    "print(d.max(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(3):\n",
    "    original=np.load('./data/npy_10000/npy/'+fnpy[k])\n",
    "    target = np.zeros(original.shape)\n",
    "    for i in range(len(original)):\n",
    "        for j in range(3):\n",
    "            target[i][j]=original[i][j]-original.mean(axis=0)[j]\n",
    "    print(target.mean(axis=0))\n",
    "    np.save('./data/npy_10000/resized/'+fnpy[k], target)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=np.load('./data/npy_10000/resized/generated_14_0_795109_part_11.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File('./data/list_1.h5')\n",
    "data = f['data'][:]\n",
    "label = f['label'][:]\n",
    "shards = f['shards'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shards.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shards[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(shards[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.squeeze(shards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shards.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=np.squeeze(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess=tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= tf.constant( [[1,1,1,1],[2,2,2,2],[3,3,3,3],[4,4,4,4],[5,5,5,5]])\n",
    "b=tf.constant([[1,2,3,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=tf.matmul(a,b,transpose_b=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
