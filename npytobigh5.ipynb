{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "from random import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make big h5 (하나당 2000개의 sample)\n",
    "fout=os.listdir(\"./data/npy_10000\")\n",
    "flist=os.listdir(\"./data/npy_10000/list\")\n",
    "max_shards=20\n",
    "list_1=flist[0:2000]\n",
    "list_2=flist[2000:4000]\n",
    "list_3=flist[4000:6000]\n",
    "list_4=flist[6000:8000]\n",
    "list_5=flist[8000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_list=[]\n",
    "combine_label=[]\n",
    "combine_size=[]\n",
    "\n",
    "a_data=np.zeros((2000*max_shards,2048,3))\n",
    "a_label=np.zeros((2000*max_shards,1),dtype=np.uint8)\n",
    "a_size=np.zeros((2000*max_shards,1),dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filelist in list_1:\n",
    "    fstr=filelist.split('_')\n",
    "#     print(fstr)\n",
    "#     filelist_label_shards_randomseed_F\n",
    "    filenames=[line.rstrip() for line in open(\"./data/npy_10000/list/\"+filelist,'r')]\n",
    "#     print(filenames)\n",
    "#     generated_shards_0_randomseed_part_partnum\n",
    "    temp_list=[]\n",
    "    temp_label=[]\n",
    "    temp_size=[]\n",
    "    for i in range(0,len(filenames)): #한 도자기 마다 생성중\n",
    "        if filenames[i]==\"\":\n",
    "            continue\n",
    "        npydata=np.load(\"./data/npy_10000/npy/\"+filenames[i]+\".npy\")\n",
    "        np.random.shuffle(npydata)\n",
    "        if npydata.shape[0]<2048:\n",
    "            continue\n",
    "        else:\n",
    "            temp_j_list=[]\n",
    "            for j in range(0,2048):\n",
    "                temp_j_list.append([npydata[j][0], npydata[j][1], npydata[j][2]])\n",
    "            \n",
    "            temp_list.append(temp_j_list)\n",
    "            temp_label.append(int(fstr[1])-1)\n",
    "            temp_size.append(int(fstr[2]))\n",
    "#         print(temp_list.shape)\n",
    "    if len(temp_list) < max_shards:\n",
    "        for i in range(max_shards-len(temp_list)):\n",
    "            temp_shuffle_list=temp_list\n",
    "#             np.random.shuffle(temp_shuffle_list)\n",
    "            temp_list.append(temp_shuffle_list[randrange(len(temp_shuffle_list))])\n",
    "            temp_label.append(int(fstr[1])-1)\n",
    "            temp_size.append(int(fstr[2]))\n",
    "    combine_list.extend(temp_list)\n",
    "    combine_label.extend(temp_label)    \n",
    "    combine_size.extend(temp_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_data=np.array(combine_list)\n",
    "a_label=np.array(combine_label)\n",
    "a_size=np.array(combine_size)\n",
    "\n",
    "f=h5py.File(\"./data/list_1.h5\",'w')\n",
    "data = f.create_dataset(\"data\", data = a_data)\n",
    "label = f.create_dataset(\"label\", data = a_label)\n",
    "shards = f.create_dataset(\"shards\", data = a_size)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_list=[]\n",
    "combine_label=[]\n",
    "combine_size=[]\n",
    "\n",
    "a_data=np.zeros((2000*max_shards,2048,3))\n",
    "a_label=np.zeros((2000*max_shards,1),dtype=np.uint8)\n",
    "a_size=np.zeros((2000*max_shards,1),dtype=np.uint8)\n",
    "\n",
    "for filelist in list_3:\n",
    "    fstr=filelist.split('_')\n",
    "#     print(fstr)\n",
    "#     filelist_label_shards_randomseed_F\n",
    "    filenames=[line.rstrip() for line in open(\"./data/npy_10000/list/\"+filelist,'r')]\n",
    "#     print(filenames)\n",
    "#     generated_shards_0_randomseed_part_partnum\n",
    "    temp_list=[]\n",
    "    temp_label=[]\n",
    "    temp_size=[]\n",
    "    for i in range(0,len(filenames)): #한 도자기 마다 생성중\n",
    "        if filenames[i]==\"\":\n",
    "            continue\n",
    "        npydata=np.load(\"./data/npy_10000/npy/\"+filenames[i]+\".npy\")\n",
    "        np.random.shuffle(npydata)\n",
    "        if npydata.shape[0]<2048:\n",
    "            continue\n",
    "        else:\n",
    "            temp_j_list=[]\n",
    "            for j in range(0,2048):\n",
    "                temp_j_list.append([npydata[j][0], npydata[j][1], npydata[j][2]])\n",
    "            \n",
    "            temp_list.append(temp_j_list)\n",
    "            temp_label.append(int(fstr[1])-1)\n",
    "            temp_size.append(int(fstr[2]))\n",
    "#         print(temp_list.shape)\n",
    "    if len(temp_list) < max_shards:\n",
    "        for i in range(max_shards-len(temp_list)):\n",
    "            temp_shuffle_list=temp_list\n",
    "#             np.random.shuffle(temp_shuffle_list)\n",
    "            temp_list.append(temp_shuffle_list[randrange(len(temp_shuffle_list))])\n",
    "            temp_label.append(int(fstr[1])-1)\n",
    "            temp_size.append(int(fstr[2]))\n",
    "    combine_list.extend(temp_list)\n",
    "    combine_label.extend(temp_label)    \n",
    "    combine_size.extend(temp_size)\n",
    "\n",
    "a_data=np.array(combine_list)\n",
    "a_label=np.array(combine_label)\n",
    "a_size=np.array(combine_size)\n",
    "\n",
    "f=h5py.File(\"./data/list_3.h5\",'w')\n",
    "data = f.create_dataset(\"data\", data = a_data)\n",
    "label = f.create_dataset(\"label\", data = a_label)\n",
    "shards = f.create_dataset(\"shards\", data = a_size)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_list=[]\n",
    "combine_label=[]\n",
    "combine_size=[]\n",
    "\n",
    "a_data=np.zeros((2000*max_shards,2048,3))\n",
    "a_label=np.zeros((2000*max_shards,1),dtype=np.uint8)\n",
    "a_size=np.zeros((2000*max_shards,1),dtype=np.uint8)\n",
    "\n",
    "for filelist in list_4:\n",
    "    fstr=filelist.split('_')\n",
    "#     print(fstr)\n",
    "#     filelist_label_shards_randomseed_F\n",
    "    filenames=[line.rstrip() for line in open(\"./data/npy_10000/list/\"+filelist,'r')]\n",
    "#     print(filenames)\n",
    "#     generated_shards_0_randomseed_part_partnum\n",
    "    temp_list=[]\n",
    "    temp_label=[]\n",
    "    temp_size=[]\n",
    "    for i in range(0,len(filenames)): #한 도자기 마다 생성중\n",
    "        if filenames[i]==\"\":\n",
    "            continue\n",
    "        npydata=np.load(\"./data/npy_10000/npy/\"+filenames[i]+\".npy\")\n",
    "        np.random.shuffle(npydata)\n",
    "        if npydata.shape[0]<2048:\n",
    "            continue\n",
    "        else:\n",
    "            temp_j_list=[]\n",
    "            for j in range(0,2048):\n",
    "                temp_j_list.append([npydata[j][0], npydata[j][1], npydata[j][2]])\n",
    "            \n",
    "            temp_list.append(temp_j_list)\n",
    "            temp_label.append(int(fstr[1])-1)\n",
    "            temp_size.append(int(fstr[2]))\n",
    "#         print(temp_list.shape)\n",
    "    if len(temp_list) < max_shards:\n",
    "        for i in range(max_shards-len(temp_list)):\n",
    "            temp_shuffle_list=temp_list\n",
    "#             np.random.shuffle(temp_shuffle_list)\n",
    "            temp_list.append(temp_shuffle_list[randrange(len(temp_shuffle_list))])\n",
    "            temp_label.append(int(fstr[1])-1)\n",
    "            temp_size.append(int(fstr[2]))\n",
    "    combine_list.extend(temp_list)\n",
    "    combine_label.extend(temp_label)    \n",
    "    combine_size.extend(temp_size)\n",
    "\n",
    "a_data=np.array(combine_list)\n",
    "a_label=np.array(combine_label)\n",
    "a_size=np.array(combine_size)\n",
    "\n",
    "f=h5py.File(\"./data/list_4.h5\",'w')\n",
    "data = f.create_dataset(\"data\", data = a_data)\n",
    "label = f.create_dataset(\"label\", data = a_label)\n",
    "shards = f.create_dataset(\"shards\", data = a_size)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_list=[]\n",
    "combine_label=[]\n",
    "combine_size=[]\n",
    "\n",
    "a_data=np.zeros((2000*max_shards,2048,3))\n",
    "a_label=np.zeros((2000*max_shards,1),dtype=np.uint8)\n",
    "a_size=np.zeros((2000*max_shards,1),dtype=np.uint8)\n",
    "\n",
    "for filelist in list_5:\n",
    "    fstr=filelist.split('_')\n",
    "#     print(fstr)\n",
    "#     filelist_label_shards_randomseed_F\n",
    "    filenames=[line.rstrip() for line in open(\"./data/npy_10000/list/\"+filelist,'r')]\n",
    "#     print(filenames)\n",
    "#     generated_shards_0_randomseed_part_partnum\n",
    "    temp_list=[]\n",
    "    temp_label=[]\n",
    "    temp_size=[]\n",
    "    for i in range(0,len(filenames)): #한 도자기 마다 생성중\n",
    "        if filenames[i]==\"\":\n",
    "            continue\n",
    "        npydata=np.load(\"./data/npy_10000/npy/\"+filenames[i]+\".npy\")\n",
    "        np.random.shuffle(npydata)\n",
    "        if npydata.shape[0]<2048:\n",
    "            continue\n",
    "        else:\n",
    "            temp_j_list=[]\n",
    "            for j in range(0,2048):\n",
    "                temp_j_list.append([npydata[j][0], npydata[j][1], npydata[j][2]])\n",
    "            \n",
    "            temp_list.append(temp_j_list)\n",
    "            temp_label.append(int(fstr[1])-1)\n",
    "            temp_size.append(int(fstr[2]))\n",
    "#         print(temp_list.shape)\n",
    "    if len(temp_list) < max_shards:\n",
    "        for i in range(max_shards-len(temp_list)):\n",
    "            temp_shuffle_list=temp_list\n",
    "#             np.random.shuffle(temp_shuffle_list)\n",
    "            temp_list.append(temp_shuffle_list[randrange(len(temp_shuffle_list))])\n",
    "            temp_label.append(int(fstr[1])-1)\n",
    "            temp_size.append(int(fstr[2]))\n",
    "    combine_list.extend(temp_list)\n",
    "    combine_label.extend(temp_label)    \n",
    "    combine_size.extend(temp_size)\n",
    "\n",
    "a_data=np.array(combine_list)\n",
    "a_label=np.array(combine_label)\n",
    "a_size=np.array(combine_size)\n",
    "\n",
    "f=h5py.File(\"./data/list_5.h5\",'w')\n",
    "data = f.create_dataset(\"data\", data = a_data)\n",
    "label = f.create_dataset(\"label\", data = a_label)\n",
    "shards = f.create_dataset(\"shards\", data = a_size)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
